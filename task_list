 * LARGE_BLOB/LARGE_TEXT
   * compare function for large types
   * generate prefix type from the large types, with specified prefix length
   * stream read interface to read them
   * stream write interface to generate a corresponding worm if the data exceeds certian bytes

 * LARGE_NUMERIC
   * generate short_numeric data type, consisting of sign bits 2, fixed sized signed integer, and variable sized blob type to store significant digits
   * generate their large_numeric counterpart, that have uint64_t as page_id of the worm following the short_numeric type, which contains the rest of the digits
   * compare function for large types
   * sign bits and the exponent are stored inline even in large types
   * you might think a large_numeric can not be compare with prefixes
   * for instance 645780623465123456.6876458076456345655946595
   * sign_bits - 2, exponent - 64 bit signed atmost, mantissa variable number of decimal in bytes
   * sign bits 00 = -infinity, 01 - negative, 10 - positive, 11 - +infinity
    so this becomes
    sign bits = 0b10, exponent 17, mantissa = 6.457806234651234566876458076456345655946595
    now you can easily truncate byte, giving us approximation, to upto some number of significant digits
    sign bits = 0b10, exponent 17, mantissa = 6.45780623
    comparison goes like first compare sign bits in binary unsigned, then exponent in signed, and then mantissa
    remaining mantissa bits can be found in the worm as 4651234566876458076456345655946595

* LARGE_JSONB
  * get -> takes var array of integers and string and makes you point to the beginning of the data in json struct
  * build a one direction readabale json serialization type, where we only need to go forward until we reach the desired type
  * create_worm
  * uses JSONparser's node as input object